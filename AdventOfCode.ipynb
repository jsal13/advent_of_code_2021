{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64661e02-db4b-4e38-90e7-838110ef11d6",
   "metadata": {},
   "source": [
    "# Advent of Code\n",
    "\n",
    "The docstrings are pretty bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "238a0511-3fd3-48fc-a60b-e1fc4e2ff3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import string\n",
    "import copy\n",
    "from datetime import datetime\n",
    "from typing import List, Tuple, Optional, Any, Callable, Dict, Set\n",
    "import textwrap\n",
    "from collections import defaultdict, Counter, deque\n",
    "from pprint import pprint\n",
    "\n",
    "from pydantic.dataclasses import dataclass, Field\n",
    "import requests as req\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06eb4b9-6961-4a41-a6b6-de0bd20c2203",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f032a9d-698f-4bd2-9f2a-f7c569e2793a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_solutions(a1sol, a2sol):\n",
    "    print(textwrap.dedent(f\"\"\"\n",
    "        a1_solution: {a1sol}\n",
    "        a2_solution: {a2sol}\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710737c0-eecf-4a39-9c4b-5f9c8e3d00a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de62ae9c-43ee-443d-a8cb-1aed8b6f90fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Advent Day 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "760cda72-98af-4082-b0c4-b85e7177e824",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a1_solution: 488\n",
      "a2_solution: 1040429\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This was a nightmare to try to do without brute-force and with trying to keep to \n",
    "# \"General\" patterns.  In truth, this can be done using a few if-else statements.\n",
    "# I wanted to practice a bit of my magic methods and the like, so I made some\n",
    "# objects which turned out to be of fairly limited use, but were fun to make.\n",
    "\n",
    "ORIG_DIGIT_ENCODINGS = list(map(set, [\"abcefg\", \"cf\", \"acdeg\",  \n",
    "\"acdfg\", \"bcdf\", \"abdfe\", \n",
    "\"abdefg\", \"acf\", \"abcdefg\", \n",
    "\"abcdfg\"]))\n",
    "\n",
    "class Digit:\n",
    "    def __init__(self, name: str, segments: str):\n",
    "        self.name = name\n",
    "        self.segments = set(segments)\n",
    "        self.length = len(self.segments)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"Digit({self.name}, {self.segments}, {self.length})\"\n",
    "        \n",
    "    def __and__(self, other):\n",
    "        return self.segments.intersection(other.segments)\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        self.name < other.name\n",
    "        \n",
    "    def __lte__(self, other):\n",
    "        self.name <= other.name\n",
    "    \n",
    "def create_digits() -> List[Digit]:\n",
    "    return [Digit(0, \"abcefg\"), Digit(1, \"cf\"), Digit(2, \"acdeg\"),  \n",
    "            Digit(3, \"acdfg\"), Digit(4, \"bcdf\"), Digit(5, \"abdfe\"), \n",
    "            Digit(6, \"abdefg\"), Digit(7, \"acf\"), Digit(8, \"abcdefg\"), \n",
    "            Digit(9, \"abcdfg\")]\n",
    "\n",
    "def parse_code_string(code_string: str) -> Tuple[Set, Set]:\n",
    "    \"\"\"Parses input of aoc_8.\"\"\"\n",
    "    code_string = code_string.split(\" | \")\n",
    "    code, output = code_string\n",
    "\n",
    "    codes = set(list(map(lambda x: \"\".join(sorted(x)), code.split(\" \"))))\n",
    "    output = list(map(lambda x: \"\".join(sorted(x)), output.split(\" \")))\n",
    "\n",
    "    return (codes, output)\n",
    "\n",
    "def determine_1478(codes: Set) -> Tuple[Dict[str, Digit], Dict[str, Digit]]:\n",
    "    possible_digits = {\"\".join(sorted(code)): sorted([digit for digit in digits if digit.length == len(code)]) \n",
    "                       for code in codes}\n",
    "    \n",
    "    matching_matches = {digit: possibilities[0].name\n",
    "                       for digit, possibilities in possible_digits.items()\n",
    "                       if len(possibilities) == 1}\n",
    "    return matching_matches, possible_digits\n",
    "\n",
    "class DigitIntersectionSignature:\n",
    "    def __init__(self, signature: str):\n",
    "        self.signature = signature\n",
    "        self.intersection_signature = [\n",
    "            len(signature.intersection(ORIG_DIGIT_ENCODINGS[i]))\n",
    "            for i in [1, 4, 7, 8]]\n",
    "        \n",
    "def decode_by_intersection_signature(code_output):\n",
    "    c, o = code_output\n",
    "    matches = determine_1478(c)[0]\n",
    "    matches_by_number = {v: set(k) for k, v in matches.items()}\n",
    "\n",
    "    digit_signatures = [DigitIntersectionSignature(sig) for sig in ORIG_DIGIT_ENCODINGS]\n",
    "    data = np.array(list(digit_signature.intersection_signature for n, digit_signature in enumerate(digit_signatures)))\n",
    "\n",
    "    encoded_values = defaultdict(int)\n",
    "    for k in c:\n",
    "        signature = [len(set(k).intersection(matches_by_number[i])) for i in [1, 4, 7, 8]]\n",
    "        encoded_values[k] = [n for n, row in enumerate(data) if (np.array(row) == signature).all()][0]\n",
    "\n",
    "    output_vals = [encoded_values[val] for val in o]\n",
    "    return int(\"\".join(map(str, output_vals)))\n",
    "\n",
    "digits = create_digits()\n",
    "\n",
    "# sample = \"\"\"be cfbegad cbdgef fgaecd cgeb fdcge agebfd fecdb fabcd edb | fdgacbe cefdb cefbgd gcbe\n",
    "# edbfga begcd cbg gc gcadebf fbgde acbgfd abcde gfcbed gfec | fcgedb cgb dgebacf gc\n",
    "# fgaebd cg bdaec gdafb agbcfd gdcbef bgcad gfac gcb cdgabef | cg cg fdcagb cbg\n",
    "# fbegcd cbd adcefb dageb afcb bc aefdc ecdab fgdeca fcdbega | efabcd cedba gadfec cb\n",
    "# aecbfdg fbg gf bafeg dbefa fcge gcbea fcaegb dgceab fcbdga | gecf egdcabf bgf bfgea\n",
    "# fgeab ca afcebg bdacfeg cfaedg gcfdb baec bfadeg bafgc acf | gebdcfa ecba ca fadegcb\n",
    "# dbcfg fgd bdegcaf fgec aegbdf ecdfab fbedc dacgb gdcebf gf | cefg dcbef fcge gbcadfe\n",
    "# bdfegc cbegaf gecbf dfcage bdacg ed bedf ced adcbefg gebcd | ed bcgafe cdgba cbgef\n",
    "# egadfb cdbfeg cegd fecab cgb gbdefca cg fgcdab egfdb bfceg | gbdfcae bgc cg cgb\n",
    "# gcafb gcf dcaebfg ecagb gf abcdeg gaef cafbge fdbac fegbdc | fgae cfgab fg bagce\"\"\"\n",
    "\n",
    "with open(\"a08.csv\", \"r\") as sample_f:\n",
    "    sample = sample_f.read()\n",
    "    \n",
    "sample_split = sample.split(\"\\n\")\n",
    "code_output_list = [parse_code_string(row) for row in sample_split]\n",
    "\n",
    "def aoc_8_a() -> int:\n",
    "    \"\"\"Solves aoc_8a.\"\"\"\n",
    "    values_1478 = defaultdict(int)\n",
    "    for codes, output in code_output_list:\n",
    "        matches = determine_1478(codes)[0]\n",
    "        for item in output:\n",
    "            if item in matches:\n",
    "                values_1478[matches[item]] += 1\n",
    "\n",
    "\n",
    "    return sum(values_1478.values())\n",
    "\n",
    "def aoc_8_b() -> int:\n",
    "    return sum(decode_by_intersection_signature(code_output) for code_output in code_output_list)\n",
    "\n",
    "print_solutions(aoc_8_a(), aoc_8_b())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c7634a-1c46-4794-8a8c-e0c9b838c552",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Advent Day 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5bc6a65f-4f8f-43c9-bb59-58c9bd1b1f2a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a1_solution: 478\n",
      "a2_solution: 1327014\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_raw = \"\"\"\n",
    "2199943210\n",
    "3987894921\n",
    "9856789892\n",
    "8767896789\n",
    "9899965678\n",
    "\"\"\".strip().split(\"\\n\")\n",
    "\n",
    "with open(\"a09.csv\", \"r\") as f:\n",
    "    data_raw = f.read().strip().split(\"\\n\")\n",
    "\n",
    "data_raw = np.array(list(map(lambda x: [int(y) for y in x], data_raw)))\n",
    "\n",
    "class SmokeMap:\n",
    "    def __init__(self, chart: np.ndarray):\n",
    "        self.chart = chart\n",
    "        self.n_rows, self.n_cols = self.chart.shape\n",
    "        \n",
    "        #!! This needs to be cleared every time.\n",
    "        # TODO: How do I deal with something like this?\n",
    "        self.basin_chart = (self.chart.copy() != 9).astype(int)\n",
    "        \n",
    "        \n",
    "    def find_neighbors(self, idx: int, jdx: int) -> List[int]:\n",
    "        \"\"\"Finds up-down-left-right neighbors of (idx, jdx).\"\"\"\n",
    "        neighbor_indices = [\n",
    "            [idx + 1, jdx],\n",
    "            [idx - 1, jdx],\n",
    "            [idx, jdx + 1],\n",
    "            [idx, jdx - 1]\n",
    "        ]\n",
    "        \n",
    "        valid_neighbor_indices = [\n",
    "            coord for coord in neighbor_indices\n",
    "            if coord[0] >= 0 and coord[0] < self.n_rows\n",
    "            and coord[1] >= 0 and coord[1] < self.n_cols\n",
    "        ]\n",
    "        \n",
    "        neighbors = [self.chart[nbidx[0], nbidx[1]] for nbidx in valid_neighbor_indices]\n",
    "        return neighbors, valid_neighbor_indices\n",
    "\n",
    "    def test_if_local_min(self, idx: int, jdx: int) -> bool:\n",
    "        \"\"\"Compares neighbors to value of (idx, jdx), sees if\n",
    "        (idx, jdx) is strictly less then all of them.\"\"\"\n",
    "        val = self.chart[idx, jdx]\n",
    "        neighbors = self.find_neighbors(idx, jdx)[0]\n",
    "        for neighbor in neighbors:\n",
    "            if neighbor <= val:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def calculate_total_risk_level(self):\n",
    "        \"\"\"Gets all local minima, adds one to its value, sums the results.\"\"\"\n",
    "        risk_level = 0\n",
    "        for row in range(self.n_rows):\n",
    "            for col in range(self.n_cols):\n",
    "                if self.test_if_local_min(row, col):\n",
    "                    risk_level += self.chart[row, col] + 1\n",
    "                    \n",
    "        return risk_level\n",
    "    \n",
    "    \n",
    "    def find_basin_size(self, idx: int, jdx: int) -> List[Tuple[int, int]]:\n",
    "        \"\"\"Finds basin around (idx, jdx) as defined \n",
    "        in https://adventofcode.com/2021/day/9#part2.\"\"\"\n",
    "        if self.basin_chart[idx, jdx] == 0:\n",
    "            return 0\n",
    "        \n",
    "        basin_size = 1\n",
    "        self.basin_chart[idx, jdx] = 0\n",
    "        neighbors = [nbr for nbr in self.find_neighbors(idx, jdx)[1]\n",
    "                     if self.basin_chart[nbr[0], nbr[1]]]\n",
    "\n",
    "        for neighbor in neighbors:    \n",
    "            basin_size += self.find_basin_size(neighbor[0], neighbor[1])\n",
    "\n",
    "        return basin_size\n",
    "    \n",
    "    def calculate_basin_sizes(self):\n",
    "        \"\"\"Gets basin sizes.\"\"\"\n",
    "        basin_sizes = []\n",
    "        for row in range(self.n_rows):\n",
    "            for col in range(self.n_cols):\n",
    "                if size := self.find_basin_size(row, col):\n",
    "                     basin_sizes.append(size)\n",
    "                    \n",
    "        return basin_sizes   \n",
    "\n",
    "sm = SmokeMap(data_raw)\n",
    "print_solutions(\n",
    "    sm.calculate_total_risk_level(), \n",
    "    math.prod(sorted(sm.calculate_basin_sizes(), reverse=True)[:3])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9fa49b-f298-409f-a51d-050447fa80a8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## Adent Day 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b7d2a3ed-6661-4050-bdd0-1f1ec3b08b89",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CHUNK_DELIMS = [[\"{\", \"[\", \"<\", \"(\"], [\"}\", \"]\", \">\", \")\"]]\n",
    "DELIMS_OPEN = dict(zip(CHUNK_DELIMS[1], CHUNK_DELIMS[0]))\n",
    "DELIMS_CLOSE = dict(zip(CHUNK_DELIMS[0], CHUNK_DELIMS[1]))\n",
    "\n",
    "class DelimString:\n",
    "    \n",
    "    def __init__(self, line: str):\n",
    "        self.line = line\n",
    "        self.stack = []\n",
    "        \n",
    "        self.is_incomplete = None\n",
    "        self.is_corrupt = None\n",
    "        self.first_illegal_character = None\n",
    "        \n",
    "        self._check_stack()\n",
    "        \n",
    "    def _clear_stack(self):\n",
    "        self.stack = []\n",
    "        \n",
    "    def _check_stack(self):\n",
    "        \"\"\"Checks stack for corruption or incompleteness.\"\"\"\n",
    "        self._clear_stack()\n",
    "        \n",
    "        for symbol in self.line:\n",
    "            # If symbol is an end delim, either we have it joining its opening\n",
    "            # or it is misaligned.\n",
    "            if symbol in \")}]>\":\n",
    "                if self.stack[-1] != DELIMS_OPEN[symbol]:\n",
    "                    # print(f\"Expected {delims_close[self.stack[-1]]} got {symbol}.\")\n",
    "                    self.is_corrupt = True\n",
    "                    self.first_illegal_character = symbol\n",
    "                    break\n",
    "                else:\n",
    "                    # Pop the corresponding opening delim.\n",
    "                    self.stack.pop()\n",
    "            else:\n",
    "                # Otherwise, it's an open delim.\n",
    "                self.stack.append(symbol)\n",
    "        \n",
    "        if self.is_corrupt is None:        \n",
    "            self.is_incomplete = len(self.stack) != 0                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "161075a8-df68-431a-882e-3a963923b84a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a1_solution: 436497\n",
      "a2_solution: 2377613374\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"a10.csv\", \"r\") as f:\n",
    "    data = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "points = {\n",
    "    \")\": 3,\n",
    "    \"]\": 57,\n",
    "    \"}\": 1197,\n",
    "    \">\": 25137\n",
    "}\n",
    "\n",
    "def aoc10_a():\n",
    "    illegal_characters = []\n",
    "    for line in data:\n",
    "        ds = DelimString(line)\n",
    "        if not ds.is_incomplete:\n",
    "            if ds.is_corrupt:\n",
    "                illegal_characters.append(points[ds.first_illegal_character])\n",
    "\n",
    "    return sum(illegal_characters)\n",
    "\n",
    "### Part 2.\n",
    "\n",
    "COMPLETION_POINTS = {\n",
    "    \")\": 1,\n",
    "    \"]\": 2,\n",
    "    \"}\": 3,\n",
    "    \">\": 4\n",
    "}\n",
    "\n",
    "def find_completion(data: List[str]) -> List[str]:\n",
    "    \"\"\"Finds delims to complete string.\"\"\"\n",
    "    incomplete = []\n",
    "    for line in data:\n",
    "        ds = DelimString(line)\n",
    "        if ds.is_incomplete:\n",
    "            incomplete.append(ds)\n",
    "\n",
    "    completions = []\n",
    "    for ds in incomplete:\n",
    "        completions.append([DELIMS_CLOSE[symbol] for symbol in ds.stack[::-1]])\n",
    "\n",
    "    return completions\n",
    "        \n",
    "def calculate_completion_score(completion: List[str]) -> int:\n",
    "    \"\"\"Calculates completion score a la AoC10.\"\"\"\n",
    "    score = 0\n",
    "    for symbol in completion:\n",
    "        score *= 5\n",
    "        score += COMPLETION_POINTS[symbol]\n",
    "\n",
    "    return score     \n",
    "\n",
    "def aoc10_b(data: List[str] = data) -> int:\n",
    "    completions = find_completion(data)\n",
    "    scores = []\n",
    "    for completion in completions:\n",
    "        scores.append(calculate_completion_score(completion))\n",
    "    return sorted(scores)[int(len(scores) / 2)]\n",
    "\n",
    "print_solutions(aoc10_a(), aoc10_b())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b6abf2-070d-4ef9-9f9c-16ff87fa444e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
